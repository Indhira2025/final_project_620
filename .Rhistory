nhanes <- NHANES
nhanes_nodup <- nhanes %>%
distinct(ID, .keep_all = TRUE)
covariates <- c('Age', 'Height', 'Weight', 'BPSysAve', 'Race1', 'Gender', 'HHIncome', 'Education', 'Depressed', 'SleepHrsNight', 'SmokeNow', 'Alcohol12PlusYr', 'TotChol', 'DirectChol')
nhanes_subset <- nhanes_nodup[, covariates]
missing_summary <- colSums(is.na(nhanes_subset))
missing_summary
missing_summary_table <- enframe(missing_summary, name = "Variable", value = "Missing Values")
name_map <- c(
"Age" = "Age (Years)",
"Height" = "Height (cm)",
"Weight" = "Weight (kg)",
"BPSysAve" = "Systolic Blood Pressure",
"Race1" = "Race",
"Gender" = "Gender",
"HHIncome" = "Household Income",
"Education" = "Education Level",
"Depressed" = "Depressed (# Days)",
"SleepHrsNight" = "Sleep (Hrs)",
"SmokeNow" = "Current Smoker",
"Alcohol12PlusYr" = "Alcohol Use (12+ Drinks/Yr)",
"TotChol" = "Total Cholesterol (mmol/L)",
"DirectChol" = "HDL (mmol/L)"
)
missing_summary_table$Variable <- mapvalues(missing_summary_table$Variable, from = names(name_map), to = name_map)
rownames(missing_summary_table) <- missing_summary_table$Variable
kable(
missing_summary_table,
caption = "Summary of Missing Values in NHANES",
format = "markdown"
)
nhanes_subset$CholRatio <- nhanes_subset$TotChol/nhanes_subset$DirectChol
nhanes_subset <- nhanes_subset %>%
mutate(Height_centered = Height - mean(Height, na.rm = TRUE),
Weight_centered = Weight - mean(Weight, na.rm = TRUE))
nhanes_filter <- na.omit(nhanes_subset)
nhanes_filter <- nhanes_subset %>%
na.omit() %>%
distinct()
categorical_vars <- c('Race1', 'Gender','SmokeNow', 'Alcohol12PlusYr')
continuous_vars <- c('Age', 'BPSysAve', 'CholRatio')
var_name_map <- c(
"Age" = "Age (Years)",
"BPSysAve" = "Systolic Blood Pressure",
"Race1" = "Race",
"Gender" = "Gender",
"SmokeNow" = "Smoking Status",
"Alcohol12PlusYr" = "Alcohol Use (12+ Drinks/Yr)",
"CholRatio" = "Total Cholesterol/HDL"
)
#plot categorical
plot_categorical <- function(var) {
ggplot() +
geom_bar(data = nhanes_subset, aes_string(x = var, fill = '"nhanes_subset"'), alpha = 0.5, position = "dodge", stat = "count") +
geom_bar(data = nhanes_filter, aes_string(x = var, fill = '"nhanes_filter"'), alpha = 0.5, position = "dodge", stat = "count") +
labs(
title = paste("Distribution of", var_name_map[[var]]),
x = var_name_map[[var]],
y = "Count"
) +
scale_fill_manual(
name = "Dataset",
values = c("nhanes_subset" = "blue", "nhanes_filter" = "orange"),
labels = c("No Missing Data", "With Missing Data")
) +
theme_minimal() +
theme(
axis.text.x = element_text(angle = 45, hjust = 1),
plot.title = element_text(size = 20),
axis.title = element_text(size = 16),
axis.text = element_text(size = 14),
legend.title = element_text(size = 16),
legend.text = element_text(size = 14)
)
}
#plot continuous
plot_continuous <- function(var) {
ggplot() +
geom_histogram(data = nhanes_subset, aes_string(x = var, fill = '"nhanes_subset"'), alpha = 0.5, bins = 30, position = "identity") +
geom_histogram(data = nhanes_filter, aes_string(x = var, fill = '"nhanes_filter"'), alpha = 0.5, bins = 30, position = "identity") +
labs(
title = paste("Distribution of", var_name_map[[var]]),
x = var_name_map[[var]],
y = "Frequency"
) +
scale_fill_manual(
name = "Dataset",
values = c("nhanes_subset" = "blue", "nhanes_filter" = "orange"),
labels = c("No Missing Data", "With Missing Data")
) +
theme_minimal() +
theme(
axis.text.x = element_text(angle = 45, hjust = 1),
plot.title = element_text(size = 20),
axis.title = element_text(size = 18),
axis.text = element_text(size = 16),
legend.title = element_text(size = 18),
legend.text = element_text(size = 16)
)
}
cat_plots <- lapply(categorical_vars, plot_categorical)
cont_plots <- lapply(continuous_vars, plot_continuous)
grid.arrange(grobs = c(cat_plots, cont_plots), ncol = 3)
set.seed(1234)
split_data <- sample.split(nhanes_filter$CholRatio, SplitRatio = 0.8)
train_data <- subset(nhanes_filter, split_data == TRUE)
test_data <- subset(nhanes_filter, split_data == FALSE)
model1 <- lm(CholRatio ~ Age + Height_centered + Weight_centered + BPSysAve + Race1 + Gender + HHIncome + Education + Depressed + SleepHrsNight + SmokeNow + Alcohol12PlusYr, data = train_data)
summary(model1)
avPlots(model1)
dwtest(model1)
plot(model1, 1)
hist(residuals(model1),
main = "Histogram of Residuals for Untransformed Model",
xlab = "Residuals")
ggplot(model1, aes(sample = rstudent(model1))) + geom_qq()
train_data$CholLog <- log(train_data$CholRatio)
modellog <- lm(CholLog ~ Age + Height + Weight + BPSysAve + Race1 + Gender+HHIncome + Education + Depressed + SleepHrsNight + SmokeNow + Alcohol12PlusYr, data = train_data)
summary(modellog)
avPlots(modellog)
dwtest(modellog)
plot(modellog, 1)
hist(residuals(modellog),
main = "Histogram of Residuals for Log Transformed Model",
xlab = "Residuals")
ggplot(modellog, aes(sample = rstudent(modellog))) + geom_qq()
vif_logmodel <- vif(modellog)
vif_logmodel
m.dffits <- dffits(modellog)
m.dfbeta <- dfbeta(modellog)
m.D <- cooks.distance(modellog)
m.covratio <- covratio(modellog)
## Get largest dffits and cooksd and dfbeta
largest_dffits <- which(abs(m.dffits) == max(abs(m.dffits)))
largest_cooksd <- which(m.D == max(m.D))
print(train_data[c(largest_dffits, largest_cooksd), ])
largest_dfbeta <- which(abs(m.dfbeta) == max(abs(m.dfbeta)))
## Get largest leverage values and internal/external studentized residuals
leverage_values <- hatvalues(modellog)
internstudentized_res <- rstandard(modellog)
externstudentized_res <- studres(modellog)
largest_leverage <- which(leverage_values == max(leverage_values, na.rm = TRUE))
largest_internstudentized_res <- which(abs(internstudentized_res) == max(abs(internstudentized_res), na.rm = TRUE))
largest_externstudentized_res <- which(abs(externstudentized_res) == max(abs(externstudentized_res), na.rm = TRUE))
print(train_data[c(largest_leverage, largest_internstudentized_res, largest_externstudentized_res), ])
# High Leverage Points
high_leverage_indices <- which(leverage_values > mean(2 * leverage_values))
print(train_data[high_leverage_indices, ])
# Remove influential and high leverage observations
diagnostic_indices <- c(largest_dffits, largest_cooksd, largest_leverage, high_leverage_indices, largest_internstudentized_res, largest_externstudentized_res)
# Remove influential observations from the dataset
noninfl_data <- train_data[-diagnostic_indices, ]
# Re-fit the model without influential observations
model_noninfl <- lm(CholLog ~ Age + Height + Weight + BPSysAve + Race1 + Gender + HHIncome + Education + Depressed + SleepHrsNight + SmokeNow + Alcohol12PlusYr, data = noninfl_data)
summary(model_noninfl)
summary(modellog)
model_int1 <- lm(CholLog ~ Age + Height + Weight + BPSysAve + Race1 + Gender + HHIncome + Education + Depressed + SleepHrsNight + SmokeNow + Alcohol12PlusYr + Depressed*Alcohol12PlusYr, data = noninfl_data)
summary(model_int1)
## Depression x Alcohol interaction p-value is significant so we will keep it.
model_int2 <- lm(CholLog ~ Age + Height + Weight + BPSysAve + Race1 + Gender + HHIncome + Education + Depressed + SleepHrsNight + SmokeNow + Alcohol12PlusYr + Depressed*Alcohol12PlusYr+Depressed*SmokeNow, data = noninfl_data)
summary(model_int2)
## Depression x Smoking interaction p-value is not significant so we will not keep it.
model_int3 <- lm(CholLog ~ Age + Height + Weight + BPSysAve + Race1 + Gender + HHIncome + Education + Depressed + SleepHrsNight + SmokeNow + Alcohol12PlusYr + Depressed*Alcohol12PlusYr+Alcohol12PlusYr*SmokeNow, data = noninfl_data)
summary(model_int3)
## Smoking x Alcohol interaction p-value is significant so we will keep it.
model_int4 <- lm(CholLog ~ Age + Height + Weight + BPSysAve + Race1 + Gender + HHIncome + Education + Depressed + SleepHrsNight + SmokeNow + Alcohol12PlusYr + Depressed*Alcohol12PlusYr+Alcohol12PlusYr*SmokeNow+Age*Gender, data = noninfl_data)
summary(model_int4)
## Age x Gender interaction p-value is significant so we will keep it.
# Backward Stepwise Selection
backward_model <- step(model_int4, direction = "backward", trace = 1)
summary(backward_model)
# Hybrid Stepwise Selection
hybrid_model <- step(model_int4, direction = "both", trace = 1)
summary(hybrid_model)
largest_dffits
largest_dfbeta
largest_internstudentized_res
largest_dfbeta
mean(2 * leverage_values)
library(NHANES)
library(car)
library(dplyr)
library(tidyr)
library(ggplot2)
library(gridExtra)
library(MASS)
library(caTools)
library(knitr)
library(plyr)
library(tibble)
library(lmtest)
nhanes <- NHANES
nhanes_nodup <- nhanes %>%
distinct(ID, .keep_all = TRUE)
covariates <- c('Age', 'Height', 'Weight', 'BPSysAve', 'Race1', 'Gender', 'HHIncome', 'Education', 'Depressed', 'SleepHrsNight', 'SmokeNow', 'Alcohol12PlusYr', 'TotChol', 'DirectChol')
nhanes_subset <- nhanes_nodup[, covariates]
missing_summary <- colSums(is.na(nhanes_subset))
missing_summary
missing_summary_table <- enframe(missing_summary, name = "Variable", value = "Missing Values")
name_map <- c(
"Age" = "Age (Years)",
"Height" = "Height (cm)",
"Weight" = "Weight (kg)",
"BPSysAve" = "Systolic Blood Pressure",
"Race1" = "Race",
"Gender" = "Gender",
"HHIncome" = "Household Income",
"Education" = "Education Level",
"Depressed" = "Depressed (# Days)",
"SleepHrsNight" = "Sleep (Hrs)",
"SmokeNow" = "Current Smoker",
"Alcohol12PlusYr" = "Alcohol Use (12+ Drinks/Yr)",
"TotChol" = "Total Cholesterol (mmol/L)",
"DirectChol" = "HDL (mmol/L)"
)
missing_summary_table$Variable <- mapvalues(missing_summary_table$Variable, from = names(name_map), to = name_map)
rownames(missing_summary_table) <- missing_summary_table$Variable
kable(
missing_summary_table,
caption = "Summary of Missing Values in NHANES",
format = "markdown"
)
nhanes_subset$CholRatio <- nhanes_subset$TotChol/nhanes_subset$DirectChol
nhanes_subset <- nhanes_subset %>%
mutate(Height_centered = Height - mean(Height, na.rm = TRUE),
Weight_centered = Weight - mean(Weight, na.rm = TRUE))
nhanes_filter <- na.omit(nhanes_subset)
nhanes_filter <- nhanes_subset %>%
na.omit() %>%
distinct()
categorical_vars <- c('Race1', 'Gender','SmokeNow', 'Alcohol12PlusYr')
continuous_vars <- c('Age', 'BPSysAve', 'CholRatio')
var_name_map <- c(
"Age" = "Age (Years)",
"BPSysAve" = "Systolic Blood Pressure",
"Race1" = "Race",
"Gender" = "Gender",
"SmokeNow" = "Smoking Status",
"Alcohol12PlusYr" = "Alcohol Use (12+ Drinks/Yr)",
"CholRatio" = "Total Cholesterol/HDL"
)
#plot categorical
plot_categorical <- function(var) {
ggplot() +
geom_bar(data = nhanes_subset, aes_string(x = var, fill = '"nhanes_subset"'), alpha = 0.5, position = "dodge", stat = "count") +
geom_bar(data = nhanes_filter, aes_string(x = var, fill = '"nhanes_filter"'), alpha = 0.5, position = "dodge", stat = "count") +
labs(
title = paste("Distribution of", var_name_map[[var]]),
x = var_name_map[[var]],
y = "Count"
) +
scale_fill_manual(
name = "Dataset",
values = c("nhanes_subset" = "blue", "nhanes_filter" = "orange"),
labels = c("No Missing Data", "With Missing Data")
) +
theme_minimal() +
theme(
axis.text.x = element_text(angle = 45, hjust = 1),
plot.title = element_text(size = 20),
axis.title = element_text(size = 16),
axis.text = element_text(size = 14),
legend.title = element_text(size = 16),
legend.text = element_text(size = 14)
)
}
#plot continuous
plot_continuous <- function(var) {
ggplot() +
geom_histogram(data = nhanes_subset, aes_string(x = var, fill = '"nhanes_subset"'), alpha = 0.5, bins = 30, position = "identity") +
geom_histogram(data = nhanes_filter, aes_string(x = var, fill = '"nhanes_filter"'), alpha = 0.5, bins = 30, position = "identity") +
labs(
title = paste("Distribution of", var_name_map[[var]]),
x = var_name_map[[var]],
y = "Frequency"
) +
scale_fill_manual(
name = "Dataset",
values = c("nhanes_subset" = "blue", "nhanes_filter" = "orange"),
labels = c("No Missing Data", "With Missing Data")
) +
theme_minimal() +
theme(
axis.text.x = element_text(angle = 45, hjust = 1),
plot.title = element_text(size = 20),
axis.title = element_text(size = 18),
axis.text = element_text(size = 16),
legend.title = element_text(size = 18),
legend.text = element_text(size = 16)
)
}
cat_plots <- lapply(categorical_vars, plot_categorical)
cont_plots <- lapply(continuous_vars, plot_continuous)
grid.arrange(grobs = c(cat_plots, cont_plots), ncol = 3)
set.seed(1234)
split_data <- sample.split(nhanes_filter$CholRatio, SplitRatio = 0.8)
train_data <- subset(nhanes_filter, split_data == TRUE)
test_data <- subset(nhanes_filter, split_data == FALSE)
model1 <- lm(CholRatio ~ Age + Height_centered + Weight_centered + BPSysAve + Race1 + Gender + HHIncome + Education + Depressed + SleepHrsNight + SmokeNow + Alcohol12PlusYr, data = train_data)
summary(model1)
avPlots(model1)
dwtest(model1)
plot(model1, 1)
hist(residuals(model1),
main = "Histogram of Residuals for Untransformed Model",
xlab = "Residuals")
ggplot(model1, aes(sample = rstudent(model1))) + geom_qq()
train_data$CholLog <- log(train_data$CholRatio)
modellog <- lm(CholLog ~ Age + Height + Weight + BPSysAve + Race1 + Gender+HHIncome + Education + Depressed + SleepHrsNight + SmokeNow + Alcohol12PlusYr, data = train_data)
summary(modellog)
avPlots(modellog)
dwtest(modellog)
plot(modellog, 1)
hist(residuals(modellog),
main = "Histogram of Residuals for Log Transformed Model",
xlab = "Residuals")
ggplot(modellog, aes(sample = rstudent(modellog))) + geom_qq()
vif_logmodel <- vif(modellog)
vif_logmodel
m.dffits <- dffits(modellog)
m.dfbeta <- dfbeta(modellog)
m.D <- cooks.distance(modellog)
m.covratio <- covratio(modellog)
## Get largest dffits and cooksd
largest_dffits <- which(abs(m.dffits) == max(abs(m.dffits)))
largest_cooksd <- which(m.D == max(m.D))
print(train_data[c(largest_dffits, largest_cooksd), ])
## Get largest leverage values and internal/external studentized residuals
leverage_values <- hatvalues(modellog)
internstudentized_res <- rstandard(modellog)
externstudentized_res <- studres(modellog)
largest_leverage <- which(leverage_values == max(leverage_values, na.rm = TRUE))
largest_internstudentized_res <- which(abs(internstudentized_res) == max(abs(internstudentized_res), na.rm = TRUE))
largest_externstudentized_res <- which(abs(externstudentized_res) == max(abs(externstudentized_res), na.rm = TRUE))
print(train_data[c(largest_leverage, largest_internstudentized_res, largest_externstudentized_res), ])
# High Leverage Points
high_leverage_indices <- which(leverage_values > mean(2 * leverage_values))
print(train_data[high_leverage_indices, ])
# Remove influential and high leverage observations
diagnostic_indices <- c(largest_dffits, largest_cooksd, largest_leverage, high_leverage_indices, largest_internstudentized_res, largest_externstudentized_res)
# Remove influential observations from the dataset
noninfl_data <- train_data[-diagnostic_indices, ]
# Re-fit the model without influential observations
model_noninfl <- lm(CholLog ~ Age + Height + Weight + BPSysAve + Race1 + Gender + HHIncome + Education + Depressed + SleepHrsNight + SmokeNow + Alcohol12PlusYr, data = noninfl_data)
summary(model_noninfl)
summary(modellog)
model_int1 <- lm(CholLog ~ Age + Height + Weight + BPSysAve + Race1 + Gender + HHIncome + Education + Depressed + SleepHrsNight + SmokeNow + Alcohol12PlusYr + Depressed*Alcohol12PlusYr, data = noninfl_data)
summary(model_int1)
## Depression x Alcohol interaction p-value is significant so we will keep it.
model_int2 <- lm(CholLog ~ Age + Height + Weight + BPSysAve + Race1 + Gender + HHIncome + Education + Depressed + SleepHrsNight + SmokeNow + Alcohol12PlusYr + Depressed*Alcohol12PlusYr+Depressed*SmokeNow, data = noninfl_data)
summary(model_int2)
## Depression x Smoking interaction p-value is not significant so we will not keep it.
model_int3 <- lm(CholLog ~ Age + Height + Weight + BPSysAve + Race1 + Gender + HHIncome + Education + Depressed + SleepHrsNight + SmokeNow + Alcohol12PlusYr + Depressed*Alcohol12PlusYr+Alcohol12PlusYr*SmokeNow, data = noninfl_data)
summary(model_int3)
## Smoking x Alcohol interaction p-value is significant so we will keep it.
model_int4 <- lm(CholLog ~ Age + Height + Weight + BPSysAve + Race1 + Gender + HHIncome + Education + Depressed + SleepHrsNight + SmokeNow + Alcohol12PlusYr + Depressed*Alcohol12PlusYr+Alcohol12PlusYr*SmokeNow+Age*Gender, data = noninfl_data)
summary(model_int4)
## Age x Gender interaction p-value is significant so we will keep it.
# Backward Stepwise Selection
backward_model <- step(model_int4, direction = "backward", trace = 1)
summary(backward_model)
# Hybrid Stepwise Selection
hybrid_model <- step(model_int4, direction = "both", trace = 1)
summary(hybrid_model)
# 1. Train-test split for prediction
set.seed(123) # Ensure reproducibility
train_indices <- sample(1:nrow(nhanes_filter), size = 0.8 * nrow(nhanes_filter))
train_data <- nhanes_filter[train_indices, ]
test_data <- nhanes_filter[-train_indices, ]
# Compute log(CholRatio) for train and test datasets
train_data$log_CholRatio <- log(train_data$CholRatio)
test_data$log_CholRatio <- log(test_data$CholRatio)
# Fit the model using the training data
final_model <- lm(log_CholRatio ~ Age + Height_centered + Weight_centered + BPSysAve + Race1 +
Gender + HHIncome + Education + Depressed + SleepHrsNight +
SmokeNow + Alcohol12PlusYr, data = train_data)
# 2. Predict log(CholRatio) on the test dataset
test_data$Predicted_log_CholRatio <- predict(final_model, newdata = test_data)
# Transform predictions back to original scale
test_data$Predicted_CholRatio <- exp(test_data$Predicted_log_CholRatio)
# 3. Compare predicted and actual CholRatio
prediction_comparison <- data.frame(
Actual = test_data$CholRatio,
Predicted = test_data$Predicted_CholRatio
)
# 4. Visualize prediction accuracy
library(ggplot2)
# Scatter plot: Actual vs Predicted CholRatio
ggplot(prediction_comparison, aes(x = Actual, y = Predicted)) +
geom_point(alpha = 0.6) +
geom_abline(slope = 1, intercept = 0, color = "red", linetype = "dashed") +
labs(
title = "Actual vs Predicted CholRatio",
x = "Actual CholRatio",
y = "Predicted CholRatio"
) +
theme_minimal()
# Residual plot: Predicted vs Residuals
test_data$Residuals <- test_data$Predicted_CholRatio - test_data$CholRatio
ggplot(test_data, aes(x = Predicted_CholRatio, y = Residuals)) +
geom_point(alpha = 0.6) +
geom_hline(yintercept = 0, color = "red", linetype = "dashed") +
labs(
title = "Residuals vs Predicted Values",
x = "Predicted CholRatio",
y = "Residuals"
) +
theme_minimal()
# 5. Evaluate model prediction performance
library(Metrics)
mse_value <- mse(test_data$CholRatio, test_data$Predicted_CholRatio)
r2_value <- cor(test_data$CholRatio, test_data$Predicted_CholRatio)^2
cat("Mean Squared Error (MSE):", mse_value, "\n")
cat("R-squared:", r2_value, "\n")
# 1. Fit interaction terms
interaction_model <- lm(log_CholRatio ~ Age * Gender + Depressed * SmokeNow + Height_centered +
Weight_centered + BPSysAve + Race1 + HHIncome + Education +
SleepHrsNight + Alcohol12PlusYr, data = train_data)
# Summary
summary(interaction_model)
cat("Significant interaction terms have p-values < 0.05 in the summary.\n")
# 2. Optimize models with stepwise selection
library(MASS)
# Perform stepwise selection on the interaction model
optimized_model <- stepAIC(interaction_model, direction = "both", trace = TRUE)
# Summary of the final optimized model
summary(optimized_model)
cat("Stepwise selection completed. The final model includes:\n")
print(names(coef(optimized_model)))
# 3. Perform K-fold cross-validation to estimate test error
library(caret)
set.seed(123) # For reproducibility
# Define cross-validation
kfold_control <- trainControl(method = "cv", number = 10)
# Perform cross-validation using caret
cv_model <- train(
formula(optimized_model),
data = train_data,
method = "lm",
trControl = kfold_control
)
# cross-validation results
cat("Cross-validation results:\n")
print(cv_model$results)
# 4. Test Log-Log regression
log_log_model <- lm(log(CholRatio) ~ log(Age) + log(Height_centered) + log(Weight_centered) +
log(BPSysAve) + Race1 + Gender + HHIncome + Education +
Depressed + SleepHrsNight + SmokeNow + Alcohol12PlusYr, data = train_data)
# Summary of the log-log model
summary(log_log_model)
# Compare models using AIC
cat("Model Comparison (AIC values):\n")
cat("Interaction Model AIC:", AIC(interaction_model), "\n")
cat("Optimized Model AIC:", AIC(optimized_model), "\n")
cat("Log-Log Model AIC:", AIC(log_log_model), "\n")
# Save model comparison results
model_comparison <- data.frame(
Model = c("Interaction Model", "Optimized Model", "Log-Log Model"),
AIC = c(AIC(interaction_model), AIC(optimized_model), AIC(log_log_model))
)
write.csv(model_comparison, "model_comparison_results.csv", row.names = FALSE)
cat("Model comparison saved to 'model_comparison_results.csv'.\n")
# Visualize
par(mfrow = c(2, 2)) # Set up plotting grid
plot(optimized_model)
file.path(getwd(), "data/coefs1.txt")
file_path <- "data/coefs1.txt"
coefs <- as.numeric(scan(file_path, what = numeric()))
fullfile_path <- file.path(getwd(), "data/coefs.txt")
coefsfullpath <- as.numeric(scan(fullfile_path, what = numeric()))
x <- seq(-5, 5, length = 100)
solve_quadratic <- function(file_path) {
coefs <- as.numeric(scan(file_path, what = numeric()))
a <- coefs[1]
b <- coefs[2]
c <- coefs[3]
discriminant <- b^2 - 4 * a * c
if (discriminant >= 0) {
solutions <- unique(c((-b + sqrt(discriminant)) / (2 * a),
(-b - sqrt(discriminant)) / (2 * a)))
} else {
solutions <- "no real solutions"
}
return(solutions)
}
for (i in 1:3) {
file_path <- paste0("data/coefs", i, ".txt")
solutions <- solve_quadratic(file_path)
print(solutions)
write(solutions, file = paste0("results/results", i, ".txt"))
}
fullfile_path <- file.path(getwd(), "data/coefs.txt")
coefsfullpath <- as.numeric(scan(fullfile_path, what = numeric()))
fullfile_path
coefsfullpath <- as.numeric(scan(fullfile_path, what = numeric()))
coefsfullpath <- as.numeric(scan(fullfile_path, what = numeric()))
fullfile_path
fullfile_path <- file.path(getwd(), "data/coefs1.txt")
coefsfullpath <- as.numeric(scan(fullfile_path, what = numeric()))
install.packages("pwr")
#install.packages("pwr")
library(pwr)
?pwr.t2n.test
library(tensorflow)
use_condaenv("tf-gpu", required = TRUE)
library(keras)
library(reticulate)
use_condaenv("tf-gpu", required = TRUE)
py_config()
install.packages("remotes")
remotes::install_github("rstudio/tensorflow")
setwd("~/MS BIOSTAT/BIOSTAT 620/final_project_620")
